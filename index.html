<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>audio</title>
  <style>
    html {
      background: no-repeat center url("bg.jpg");
      background-size: cover;
      height: 100%;
    }

    body {
      margin: 0;
    }

    input {
      width: 500px;
      border: solid 1px #ddd;
      border-radius: 5px;
      padding: 1.5em;
      outline: 0;
    }
  </style>
  <!-- <script src="https://wusfen.github.io/console.js/dist/console.js"></script> -->

</head>

<body>
  <script>
    // 画布
    var canvas = document.createElement('canvas')
    document.body.appendChild(canvas)
    canvas.style.position = 'absolute'
    canvas.style.width = '100%'
    canvas.style.height = '100%'
    canvas.style.color = 'rgb(250, 250, 255)'
    canvas.style.borderColor = 'rgba(255, 255, 255, 0.5)'
    canvas.style.outlineColor = 'rgb(255, 128, 226)'

    var ctx = canvas.getContext('2d')


    // 音频上下文
    AudioContext = window.AudioContext || window.webkitAudioContext
    var audioContext = new AudioContext()
    // 音频源节点
    // var mediaElementAudioSourceNode = new MediaElementAudioSourceNode(audioContext, {mediaElement: document.getElementById('audio')})
    // 音频分析节点
    var analyserNode = audioContext.createAnalyser()
    // 源节点连接分析节点
    // mediaElementAudioSourceNode.connect(analyserNode)
    // 连接扬声器
    // analyserNode.connect(audioContext.destination)

    // 麦克风
    navigator.mediaDevices.getUserMedia({ audio: true })
      .then(function (stream) {
        console.log('getUserMedia', stream)
        // 媒体流源节点
        var mediaStreamAudioSourceNode = audioContext.createMediaStreamSource(stream)
        // // 音频分析节点
        // var analyserNode = audioContext.createAnalyser()
        // 连接分析节点
        mediaStreamAudioSourceNode.connect(analyserNode)
        // // 画图
        // draw(analyserNode)
      })
      .catch(function (e) {
        console.error('getUserMedia', e)
      })

    // 画图
    draw(analyserNode)

    // 循环获取频谱可视化
    function draw(analyserNode) {
      var width = 2048
      // reset
      canvas.width = width
      canvas.height = width

      ctx.lineWidth = 2
      ctx.lineCap = 'round'

      // 阴影
      ctx.shadowOffsetX = 15
      ctx.shadowOffsetY = 100
      ctx.shadowBlur = 25
      ctx.shadowColor = canvas.style.outlineColor

      // 分析节点取样
      analyserNode.fftSize = width * 2

      // 波形数据
      var array = new Uint8Array(analyserNode.frequencyBinCount)
      analyserNode.getByteTimeDomainData(array)

      ctx.strokeStyle = canvas.style.borderColor
      ctx.beginPath()
      array.forEach(function (y, x) {
        ctx.lineTo(x, width / 2 + (y - 128) * 1.5)
      })
      ctx.stroke()

      // 频谱数据
      var array = new Uint8Array(analyserNode.frequencyBinCount)
      analyserNode.getByteFrequencyData(array)
      // console.log(array)

      // 一半
      ctx.strokeStyle = canvas.style.color
      ctx.fillStyle = canvas.style.color
      ctx.beginPath()
      // ctx.lineTo(width / 2, 0)
      array.forEach(function (y, x) {
        ctx.lineTo(y + (width / 2) + 0, x)
      })
      // ctx.fill()
      ctx.stroke()

      // 另一半
      ctx.strokeStyle = canvas.style.color
      ctx.fillStyle = canvas.style.color
      ctx.beginPath()
      // ctx.lineTo((width / 2), 0)
      array.forEach(function (y, x) {
        ctx.lineTo((width / 2) - y - 0, x)
      })
      // ctx.fill()
      ctx.stroke()

      // 循环
      setTimeout(() => {
        draw(analyserNode)
      }, draw.timeGap || 16)
    }

  </script>
</body>

</html>